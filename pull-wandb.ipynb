{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "def get_history(user=\"kealexanderwang\", project=\"constrained-pnns\", query={},\n",
    "                **kwargs):\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(path=f\"{user}/{project}\", filters=query)\n",
    "    dataframes = [run.history(**kwargs) for run in runs]\n",
    "    return list(zip(runs, dataframes))\n",
    "\n",
    "\n",
    "def download_files(user=\"kealexanderwang\", project=\"constrained-pnns\",\n",
    "                   query={}, save_dir=\".\", **kwargs):\n",
    "    \"\"\"\n",
    "    Download the files of each run into a new directory for the run.\n",
    "    Also saves the config dict of the run.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(path=f\"{user}/{project}\", filters=query)\n",
    "    for run in runs:\n",
    "        name = run.name\n",
    "        config = run.config\n",
    "\n",
    "        run_dir = os.path.join(save_dir, name)\n",
    "        if not os.path.isdir(run_dir):\n",
    "            os.mkdir(run_dir)\n",
    "\n",
    "        with open(os.path.join(run_dir, \"config.pkl\"), \"wb\") as h:\n",
    "            pickle.dump(config, h)\n",
    "\n",
    "        files = run.files()\n",
    "        for file in files:\n",
    "            file.download(root=run_dir)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pl_trainer import DynamicsModel, SaveTestLogCallback\n",
    "import os\n",
    "import pprint \n",
    "\n",
    "def load_model_from_run(run, save_dir=\"/tmp\"):\n",
    "    name = run.display_name\n",
    "    ckpt_save_path = os.path.join(save_dir, name)\n",
    "    if not os.path.exists(ckpt_save_path):\n",
    "        os.makedirs(ckpt_save_path)\n",
    "     \n",
    "    ckpts = sorted([f for f in run.files() if \"checkpoints\" in f.name])\n",
    "    if len(ckpts) == 0:\n",
    "        raise RuntimeError(f\"Run {name} has no checkpoints!\")\n",
    "    # pick latest checkpoint if available\n",
    "    last_ckpt = ckpts[-1]\n",
    "    last_ckpt.download(replace=True, root=ckpt_save_path)\n",
    "        \n",
    "    ckpt_path = os.path.join(ckpt_save_path, last_ckpt.name)\n",
    "    # Uncommet if you need the trainer\n",
    "    # trainer = Trainer(resume_from_checkpoint=ckpt_path,logger=False)\n",
    "    pl_trainer = None\n",
    "    pl_model = DynamicsModel.load_from_checkpoint(ckpt_path)\n",
    "\n",
    "    pp = pprint.PrettyPrinter(indent=4)\n",
    "    print(\"Model Hyperparameters:\")\n",
    "    pp.pprint(vars(pl_model.hparams))\n",
    "    return pl_trainer, pl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.1746e-06)\n",
      "NN ignores wgrad\n",
      "NN currently assumes time independent ODE\n",
      "Model Hyperparameters:\n",
      "{   'angular_dims': range(0, 3),\n",
      "    'batch_size': 800,\n",
      "    'body_args': [3],\n",
      "    'body_class': 'ChainPendulum',\n",
      "    'callbacks': [   <pytorch_lightning.callbacks.lr_logger.LearningRateLogger object at 0x7f0ffc0b1f10>,\n",
      "                     <pl_trainer.SaveTestLogCallback object at 0x7f0ffc0429d0>,\n",
      "                     <pytorch_lightning.callbacks.progress.ProgressBar object at 0x7f0ffc042a50>],\n",
      "    'check_val_every_n_epoch': 100,\n",
      "    'chunk_len': 5,\n",
      "    'ckpt_dir': '/home/alex_w/repos/hamiltonian-biases/experiments/ChainPendulumn3m1l1/NN/wandb/run-20200505_204111-2l6n8uf7/constrained-pnns/version_2l6n8uf7/checkpoints',\n",
      "    'dataset_class': 'RigidBodyDataset',\n",
      "    'debug': False,\n",
      "    'dof_ndim': 3,\n",
      "    'dt': 0.1,\n",
      "    'euclidean': False,\n",
      "    'exp_dir': '/home/alex_w/repos/hamiltonian-biases/experiments/ChainPendulumn3m1l1/NN',\n",
      "    'fast_dev_run': False,\n",
      "    'gpus': 1,\n",
      "    'hidden_size': 200,\n",
      "    'integration_time': 10.0,\n",
      "    'logger': <pytorch_lightning.loggers.wandb.WandbLogger object at 0x7f0ffbfd92d0>,\n",
      "    'lr': 0.001,\n",
      "    'max_epochs': 2000,\n",
      "    'n_epochs': 2000,\n",
      "    'n_epochs_per_val': 100,\n",
      "    'n_gpus': 1,\n",
      "    'n_hidden': 200,\n",
      "    'n_layers': 3,\n",
      "    'n_test': 100,\n",
      "    'n_train': 800,\n",
      "    'n_val': 100,\n",
      "    'network_class': 'NN',\n",
      "    'no_lr_sched': False,\n",
      "    'num_layers': 3,\n",
      "    'optimizer_class': 'AdamW',\n",
      "    'regen': False,\n",
      "    'seed': 0,\n",
      "    'tags': ['tune', '3pendulum'],\n",
      "    'tol': 1e-07,\n",
      "    'weight_decay': 0.0001,\n",
      "    'wgrad': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/miniconda3/envs/ham37v2/lib/python3.7/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/alex/miniconda3/envs/ham37v2/lib/python3.7/site-packages/torch/serialization.py:657: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Softplus' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "# See https://docs.wandb.com/library/reference/wandb_api for how to write queries\n",
    "query = {\"tags\": {\"$eq\": \"3pendulum\"}}\n",
    "runs, histories = zip(*get_history(query=query))\n",
    "pl_trainer, pl_model = load_model_from_run(runs[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
